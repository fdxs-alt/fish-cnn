{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[WindowsPath('fishes/Fish_Dataset/Fish_Dataset/Black Sea Sprat/Black Sea Sprat/00001.png'),\n WindowsPath('fishes/Fish_Dataset/Fish_Dataset/Black Sea Sprat/Black Sea Sprat/00002.png'),\n WindowsPath('fishes/Fish_Dataset/Fish_Dataset/Black Sea Sprat/Black Sea Sprat/00003.png'),\n WindowsPath('fishes/Fish_Dataset/Fish_Dataset/Black Sea Sprat/Black Sea Sprat/00004.png'),\n WindowsPath('fishes/Fish_Dataset/Fish_Dataset/Black Sea Sprat/Black Sea Sprat/00005.png'),\n WindowsPath('fishes/Fish_Dataset/Fish_Dataset/Black Sea Sprat/Black Sea Sprat/00006.png'),\n WindowsPath('fishes/Fish_Dataset/Fish_Dataset/Black Sea Sprat/Black Sea Sprat/00007.png'),\n WindowsPath('fishes/Fish_Dataset/Fish_Dataset/Black Sea Sprat/Black Sea Sprat/00008.png'),\n WindowsPath('fishes/Fish_Dataset/Fish_Dataset/Black Sea Sprat/Black Sea Sprat/00009.png'),\n WindowsPath('fishes/Fish_Dataset/Fish_Dataset/Black Sea Sprat/Black Sea Sprat/00010.png')]"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting the list of files\n",
    "from pathlib import Path\n",
    "\n",
    "fish_dir = Path('./fishes/Fish_Dataset/Fish_Dataset')\n",
    "file_path = list(fish_dir.glob(r\"**/*.png\"))\n",
    "\n",
    "file_path[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Black Sea Sprat', 'Black Sea Sprat GT', 'Gilt-Head Bream',\n       'Gilt-Head Bream GT', 'Hourse Mackerel', 'Hourse Mackerel GT',\n       'Red Mullet', 'Red Mullet GT', 'Red Sea Bream', 'Red Sea Bream GT',\n       'Sea Bass', 'Sea Bass GT', 'Shrimp', 'Shrimp GT',\n       'Striped Red Mullet', 'Striped Red Mullet GT', 'Trout', 'Trout GT'],\n      dtype=object)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting the labels of the images\n",
    "from os import path\n",
    "import pandas as pd\n",
    "\n",
    "labels = list(map(lambda f: path.split(path.split(f)[0])[1], file_path))\n",
    "\n",
    "labels = pd.Series(labels)\n",
    "labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    fishes\\Fish_Dataset\\Fish_Dataset\\Black Sea Spr...\n1    fishes\\Fish_Dataset\\Fish_Dataset\\Black Sea Spr...\n2    fishes\\Fish_Dataset\\Fish_Dataset\\Black Sea Spr...\n3    fishes\\Fish_Dataset\\Fish_Dataset\\Black Sea Spr...\n4    fishes\\Fish_Dataset\\Fish_Dataset\\Black Sea Spr...\ndtype: object"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Images series\n",
    "images = pd.Series(file_path).astype(str)\n",
    "images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(9000, 2)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating dataframe of fishes with their labels\n",
    "fishes = pd.concat([images, labels], axis=1)\n",
    "fishes.columns = [\"image\", \"label\"]\n",
    "fishes = fishes[fishes[\"label\"].apply(lambda x: x[-2:] != \"GT\")].sample(frac=1).reset_index(drop=True)\n",
    "fishes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8100, 2)\n",
      "(900, 2)\n"
     ]
    }
   ],
   "source": [
    "## Splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(fishes, test_size=0.1, random_state=15, shuffle=True)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrimp                911\n",
      "Black Sea Sprat       905\n",
      "Red Sea Bream         904\n",
      "Red Mullet            902\n",
      "Sea Bass              898\n",
      "Hourse Mackerel       898\n",
      "Trout                 897\n",
      "Striped Red Mullet    893\n",
      "Gilt-Head Bream       892\n",
      "Name: label, dtype: int64\n",
      "###\n",
      "Gilt-Head Bream       108\n",
      "Striped Red Mullet    107\n",
      "Trout                 103\n",
      "Hourse Mackerel       102\n",
      "Sea Bass              102\n",
      "Red Mullet             98\n",
      "Red Sea Bream          96\n",
      "Black Sea Sprat        95\n",
      "Shrimp                 89\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.label.value_counts())\n",
    "print(\"###\")\n",
    "print(test_data.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6885 validated image filenames belonging to 9 classes.\n",
      "Found 1215 validated image filenames belonging to 9 classes.\n",
      "Found 900 validated image filenames belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "## Image Generator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_size = (224, 224)\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1. / 255, validation_split=0.15)\n",
    "test_gen = ImageDataGenerator()\n",
    "\n",
    "train_images = train_gen.flow_from_dataframe(dataframe=train_data,\n",
    "                                             x_col=\"image\",\n",
    "                                             y_col=\"label\",\n",
    "                                             target_size=img_size,\n",
    "                                             class_mode=\"categorical\",\n",
    "                                             batch_size=32,\n",
    "                                             subset=\"training\",\n",
    "                                             seed=15,\n",
    "                                             color_mode=\"rgb\",\n",
    "                                             shuffle=True)\n",
    "\n",
    "validation_images = train_gen.flow_from_dataframe(dataframe=train_data,\n",
    "                                                  x_col=\"image\",\n",
    "                                                  y_col=\"label\",\n",
    "                                                  target_size=img_size,\n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                  batch_size=32,\n",
    "                                                  subset=\"validation\",\n",
    "                                                  seed=15,\n",
    "                                                  color_mode=\"rgb\",\n",
    "                                                  shuffle=True)\n",
    "\n",
    "test_images = test_gen.flow_from_dataframe(dataframe=test_data,\n",
    "                                           x_col=\"image\",\n",
    "                                           y_col=\"label\",\n",
    "                                           target_size=img_size,\n",
    "                                           class_mode=\"categorical\",\n",
    "                                           batch_size=32,\n",
    "                                           color_mode=\"rgb\",\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 394272)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               50466944  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,485,513\n",
      "Trainable params: 50,485,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout, Flatten, Dense, Conv2D\n",
    "\n",
    "model = Sequential([Conv2D(32, (3, 3), activation='relu', strides=(1, 1), input_shape=input_shape),\n",
    "                    MaxPooling2D(pool_size=(2, 2)), Flatten(),\n",
    "                    Dense(128, activation='relu'), Dropout(0.1),\n",
    "                    Dense(128, activation='relu'), Dropout(0.1), Dense(9, activation=\"softmax\")])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "\n",
    "rate_reduction = ReduceLROnPlateau(monitor=\"val_accuracy\", patience=5, verbose=1, factor=0.2, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', patience=1, restore_best_weights=True)\n",
    "csv_logger = CSVLogger(\"model_history_log.csv\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "216/216 [==============================] - 157s 724ms/step - loss: 2.4958 - accuracy: 0.4107 - val_loss: 0.8634 - val_accuracy: 0.7128 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "216/216 [==============================] - 97s 449ms/step - loss: 0.5882 - accuracy: 0.7993 - val_loss: 0.2000 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "216/216 [==============================] - 97s 448ms/step - loss: 0.2196 - accuracy: 0.9278 - val_loss: 0.1355 - val_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "216/216 [==============================] - 96s 443ms/step - loss: 0.1258 - accuracy: 0.9566 - val_loss: 0.0401 - val_accuracy: 0.9885 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "216/216 [==============================] - 95s 440ms/step - loss: 0.0712 - accuracy: 0.9768 - val_loss: 0.0467 - val_accuracy: 0.9852 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "216/216 [==============================] - 99s 460ms/step - loss: 0.0661 - accuracy: 0.9784 - val_loss: 0.0326 - val_accuracy: 0.9901 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "216/216 [==============================] - 101s 469ms/step - loss: 0.0525 - accuracy: 0.9827 - val_loss: 0.0315 - val_accuracy: 0.9918 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "216/216 [==============================] - 102s 473ms/step - loss: 0.0542 - accuracy: 0.9813 - val_loss: 0.0761 - val_accuracy: 0.9778 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "216/216 [==============================] - 101s 469ms/step - loss: 0.0494 - accuracy: 0.9836 - val_loss: 0.0416 - val_accuracy: 0.9860 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "216/216 [==============================] - 99s 457ms/step - loss: 0.0368 - accuracy: 0.9891 - val_loss: 0.0271 - val_accuracy: 0.9909 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "216/216 [==============================] - 95s 441ms/step - loss: 0.0406 - accuracy: 0.9865 - val_loss: 0.0590 - val_accuracy: 0.9844 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "216/216 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9875\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "216/216 [==============================] - 97s 448ms/step - loss: 0.0344 - accuracy: 0.9875 - val_loss: 0.0342 - val_accuracy: 0.9868 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "216/216 [==============================] - 96s 442ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.0159 - val_accuracy: 0.9951 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "216/216 [==============================] - 95s 441ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.0184 - val_accuracy: 0.9942 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "216/216 [==============================] - 95s 441ms/step - loss: 0.0151 - accuracy: 0.9936 - val_loss: 0.0168 - val_accuracy: 0.9942 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "216/216 [==============================] - 95s 440ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0140 - val_accuracy: 0.9951 - lr: 2.0000e-04\n",
      "Epoch 17/50\n",
      "216/216 [==============================] - 95s 439ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0215 - val_accuracy: 0.9926 - lr: 2.0000e-04\n",
      "Epoch 18/50\n",
      "216/216 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9964\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "216/216 [==============================] - 95s 440ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.0194 - val_accuracy: 0.9926 - lr: 2.0000e-04\n",
      "Epoch 19/50\n",
      "216/216 [==============================] - 95s 439ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0179 - val_accuracy: 0.9959 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, validation_data=validation_images, epochs=50, verbose=1,\n",
    "                    callbacks=[rate_reduction, early_stop, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "prediction = np.argmax(model.predict(test_images), axis=1)\n",
    "predicted_labels = test_images.class_indices\n",
    "predicted_labels = dict((v, k) for k, v in predicted_labels.items())\n",
    "predictions = [predicted_labels[k] for k in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "   Black Sea Sprat       1.00      0.95      0.97        95\n",
      "   Gilt-Head Bream       1.00      0.94      0.97       108\n",
      "   Hourse Mackerel       1.00      0.99      1.00       102\n",
      "        Red Mullet       1.00      1.00      1.00        98\n",
      "     Red Sea Bream       0.99      1.00      0.99        96\n",
      "          Sea Bass       0.96      1.00      0.98       102\n",
      "            Shrimp       0.99      1.00      0.99        89\n",
      "Striped Red Mullet       1.00      0.95      0.98       107\n",
      "             Trout       0.90      1.00      0.95       103\n",
      "\n",
      "          accuracy                           0.98       900\n",
      "         macro avg       0.98      0.98      0.98       900\n",
      "      weighted avg       0.98      0.98      0.98       900\n",
      "\n",
      "0.9811111111111112\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.94736842, 0.        , 0.        , 0.        , 0.        ,\n        0.04210526, 0.        , 0.        , 0.01052632],\n       [0.        , 0.94444444, 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.05555556],\n       [0.        , 0.        , 0.99019608, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.00980392],\n       [0.        , 0.        , 0.        , 1.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 1.        ,\n        0.        , 0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        1.        , 0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.00934579,\n        0.        , 0.00934579, 0.95327103, 0.02803738],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 1.        ]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "y_test = test_data.label\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(accuracy_score(y_test, predictions))\n",
    "confusion_matrix(y_test, predictions, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved successfully\n"
     ]
    }
   ],
   "source": [
    "from tensorflowjs import converters\n",
    "\n",
    "converters.save_keras_model(model, \"tf-js-model\")\n",
    "\n",
    "print(\"Saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fishes\\\\Fish_Dataset\\\\Fish_Dataset\\\\Striped Red Mullet\\\\Striped Red Mullet\\\\00167.png', 'fishes\\\\Fish_Dataset\\\\Fish_Dataset\\\\Hourse Mackerel\\\\Hourse Mackerel\\\\00009.png', 'fishes\\\\Fish_Dataset\\\\Fish_Dataset\\\\Hourse Mackerel\\\\Hourse Mackerel\\\\00098.png', 'fishes\\\\Fish_Dataset\\\\Fish_Dataset\\\\Shrimp\\\\Shrimp\\\\00276.png', 'fishes\\\\Fish_Dataset\\\\Fish_Dataset\\\\Shrimp\\\\Shrimp\\\\00338.png', 'fishes\\\\Fish_Dataset\\\\Fish_Dataset\\\\Black Sea Sprat\\\\Black Sea Sprat\\\\00193.png']\n",
      "['Striped Red Mullet', 'Hourse Mackerel', 'Hourse Mackerel', 'Shrimp', 'Shrimp', 'Black Sea Sprat']\n"
     ]
    }
   ],
   "source": [
    "print(test_images.filenames[:6])\n",
    "print(predictions[:6])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}